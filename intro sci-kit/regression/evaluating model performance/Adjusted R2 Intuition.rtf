{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww18860\viewh12000\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs34 \cf0 Adjusted R2\
\
R^2 applies the same way as it does to univariate linear regression, as it does to multivariate linear regression. The goal again for R^2 is to reduce the difference between the predictions from our fitted regression line, from the average line.\
\
R^2 = 1 - SSres/SStot\
\
So, for multivariate linear regression, R^2 works in the same way\'85 except there is one \'93problem\'94. That problem is when you add a feature to your independent variables, no matter what happens, R^2 will not decrease.\
\
y = b0x0 + b1x1 + b2x2\
\
Now that we\'92ve added b2x2, we added a whole feature (x2) and now we run an algorithm like gradient descent to find that the value we\'92ve added is wholly insignificant (and therefore hurts the model). So, gradient descent ends up applying a coefficient b2 that that is very close to 0. In this process, we end up never decreasing R^2\'92s value \'97 if anything, it will only increase if gradient descent finds that the cost function is continually be reduced by adding in the feature.\
\
So\'85 where\'92s the problem, you may ask? Well, if we keep adding features to our dataset, we will never know if they are actually hurting us at all because R^2 never decreases. For that reason, we need a new measure that will tell us if an added independent variable (feature) is of no use to us.\
\
Introducing Adjusted R^2\
\
Adj R^2 = 1 - (1 - R^2) * (n-1)/(n - p - 1)\
\
n = number of training examples\
p = number of features\
\
As you can see, if you increase the amount of features, (n - p - 1) decreases, causing the (n-1)/(n-p-1) term to increase.\
\
If 1 - R^2 increases:\
	Adj R^2 increases // model got better\
elif 1 - R^2 increases at a rate less than the decrease:\
	Adj R^2 decreases // model got worse\
\
}