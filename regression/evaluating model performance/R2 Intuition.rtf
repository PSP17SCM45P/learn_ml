{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs34 \cf0 R Squared Intuition\
\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\
R squared is a statistical measure that defines how far the fitted, learned regression line is from the average line.\
\
Machine learning algorithms work in the way of reducing euclidean distances, and so in ordinary least squares we see the following play out:\
\
SSres = SUM (y(i) - y^(i))^2\
SStot =  SUM (y(i) - y_avg(i))^2\
\
** SSres \'97> Sum of Squares Residuals (in between 0 and 1)\
** SStot  \'97> Sum of Squares Total \
\
R^2 = 1 - SSres/SStot\
\
This tells us how good our fitted line is against the average.\
\
Goal: have R^2 as close as possible to 1, meaning you get reduce your sum of squares residuals as much as possible\
\
\
}